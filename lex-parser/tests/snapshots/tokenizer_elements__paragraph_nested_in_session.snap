---
source: lex-parser/tests/tokenizer_elements.rs
expression: tokens
---
[
    (
        Text(
            "Paragraphs",
        ),
        0..10,
    ),
    (
        Whitespace(
            1,
        ),
        10..11,
    ),
    (
        Text(
            "can",
        ),
        11..14,
    ),
    (
        Whitespace(
            1,
        ),
        14..15,
    ),
    (
        Text(
            "contain",
        ),
        15..22,
    ),
    (
        Whitespace(
            1,
        ),
        22..23,
    ),
    (
        Text(
            "numbers",
        ),
        23..30,
    ),
    (
        Colon,
        30..31,
    ),
    (
        Whitespace(
            1,
        ),
        31..32,
    ),
    (
        Number(
            "123",
        ),
        32..35,
    ),
    (
        Comma,
        35..36,
    ),
    (
        Whitespace(
            1,
        ),
        36..37,
    ),
    (
        Number(
            "456",
        ),
        37..40,
    ),
    (
        Comma,
        40..41,
    ),
    (
        Whitespace(
            1,
        ),
        41..42,
    ),
    (
        Number(
            "789",
        ),
        42..45,
    ),
    (
        BlankLine(
            Some(
                "\n",
            ),
        ),
        45..46,
    ),
]
