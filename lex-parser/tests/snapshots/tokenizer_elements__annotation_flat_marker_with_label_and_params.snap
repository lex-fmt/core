---
source: lex-parser/tests/tokenizer_elements.rs
expression: tokens
---
[
    (
        LexMarker,
        0..2,
    ),
    (
        Whitespace(
            1,
        ),
        2..3,
    ),
    (
        Text(
            "warning",
        ),
        3..10,
    ),
    (
        Whitespace(
            1,
        ),
        10..11,
    ),
    (
        Text(
            "severity",
        ),
        11..19,
    ),
    (
        Equals,
        19..20,
    ),
    (
        Text(
            "high",
        ),
        20..24,
    ),
    (
        Whitespace(
            1,
        ),
        24..25,
    ),
    (
        LexMarker,
        25..27,
    ),
    (
        Whitespace(
            1,
        ),
        27..28,
    ),
    (
        Text(
            "Check",
        ),
        28..33,
    ),
    (
        Whitespace(
            1,
        ),
        33..34,
    ),
    (
        Text(
            "this",
        ),
        34..38,
    ),
    (
        Whitespace(
            1,
        ),
        38..39,
    ),
    (
        Text(
            "carefully",
        ),
        39..48,
    ),
    (
        BlankLine(
            Some(
                "\n",
            ),
        ),
        48..49,
    ),
]
