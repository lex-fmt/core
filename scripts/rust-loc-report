#!/usr/bin/env bash
# Generate LOC report from cargo warloc output
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
cd "$PROJECT_ROOT"

# Save cargo warloc output to temp file and read it
TMPFILE=$(mktemp)
trap "rm -f $TMPFILE" EXIT

cargo warloc --by-file > "$TMPFILE"

python3 << PYTHON_EOF
import re
import sys
from collections import defaultdict

# Read from temp file passed as argument
with open('$TMPFILE', 'r') as f:
    content = f.read()

# Parse files
files = []
current_file = None
current_main_code = 0
current_test_code = 0

for i, line in enumerate(content.split('\n')):
    # Skip summary sections at the end
    if 'File count:' in line:
        break
        
    if line.startswith('File name:'):
        # Store previous file if exists
        if current_file is not None:
            files.append({
                'name': current_file, 
                'main_code': current_main_code, 
                'test_code': current_test_code
            })
        
        # Extract file name
        match = re.match(r'File name: \.(/.*)', line)
        if match:
            current_file = match.group(1)
            current_main_code = 0
            current_test_code = 0
    elif current_file and line.startswith('Main') and '|' in line:
        # Extract Main code lines
        parts = [p.strip() for p in line.split('|')]
        if len(parts) >= 2:
            try:
                current_main_code = int(parts[1])
            except ValueError:
                current_main_code = 0
    elif current_file and line.startswith('Tests') and '|' in line:
        # Extract Tests code lines
        parts = [p.strip() for p in line.split('|')]
        if len(parts) >= 2:
            try:
                current_test_code = int(parts[1])
            except ValueError:
                current_test_code = 0

# Don't forget the last file
if current_file is not None:
    files.append({
        'name': current_file, 
        'main_code': current_main_code, 
        'test_code': current_test_code
    })

# Generate the file-based table
print('# Loc Counts lex')
print()
print('Here\'s the table showing LOC counts for all files:')
print()
print('| File name | Code | Tests | Total |')
print('| --- | --- | --- | --- |')
for f in files:
    total = f['main_code'] + f['test_code']
    # Remove leading ./ and format name
    name = f['name'].replace('./', '')
    # Remove leading / as well
    if name.startswith('/'):
        name = name[1:]
    if len(name) > 60:
        name = name[:57] + '...'
    print(f"| {name} | {f['main_code']} | {f['test_code']} | {total} |")

# Calculate totals
total_code = sum(f['main_code'] for f in files)
total_tests = sum(f['test_code'] for f in files)
total_all = total_code + total_tests
print(f"| TOTAL ({len(files)} files) | {total_code} | {total_tests} | {total_all} |")
print()
print()

# Now generate directory aggregation
dir_totals = defaultdict(lambda: {'code': 0, 'tests': 0})
for f in files:
    path_parts = f['name'].replace('./', '').split('/')
    # Remove empty first part if it was just /
    if not path_parts[0]:
        path_parts = path_parts[1:]
    # Add to all directory levels
    for i in range(1, len(path_parts)):
        dir_path = '/'.join(path_parts[:i])
        dir_totals[dir_path]['code'] += f['main_code']
        dir_totals[dir_path]['tests'] += f['test_code']

# Sort directories by depth and name
def dir_sort_key(d):
    parts = d.split('/')
    return (len(parts), d)

sorted_dirs = sorted(dir_totals.keys(), key=dir_sort_key)

print('## Directory Aggregation')
print()
print('| Directory | Code | Tests | Total |')
print('| --- | --- | --- | --- |')
for d in sorted_dirs:
    code = dir_totals[d]['code']
    tests = dir_totals[d]['tests']
    total = code + tests
    print(f"| {d}/ | {code} | {tests} | {total} |")

print(f"| TOTAL (aggregated by directory) | {total_code} | {total_tests} | {total_all} |")
PYTHON_EOF

