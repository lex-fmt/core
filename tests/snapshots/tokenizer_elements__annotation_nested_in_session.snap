---
source: tests/tokenizer_elements.rs
expression: tokens.tokens()
---
[
    (
        LexMarker,
        0..2,
    ),
    (
        Whitespace,
        2..3,
    ),
    (
        Text(
            "note",
        ),
        3..7,
    ),
    (
        Whitespace,
        7..8,
    ),
    (
        Text(
            "author",
        ),
        8..14,
    ),
    (
        Equals,
        14..15,
    ),
    (
        Quote,
        15..16,
    ),
    (
        Text(
            "Jane",
        ),
        16..20,
    ),
    (
        Whitespace,
        20..21,
    ),
    (
        Text(
            "Doe",
        ),
        21..24,
    ),
    (
        Quote,
        24..25,
    ),
    (
        Whitespace,
        25..26,
    ),
    (
        LexMarker,
        26..28,
    ),
    (
        Newline,
        28..29,
    ),
    (
        Indent(
            [
                (
                    Indentation,
                    29..33,
                ),
            ],
        ),
        0..0,
    ),
    (
        Text(
            "This",
        ),
        33..37,
    ),
    (
        Whitespace,
        37..38,
    ),
    (
        Text(
            "is",
        ),
        38..40,
    ),
    (
        Whitespace,
        40..41,
    ),
    (
        Text(
            "an",
        ),
        41..43,
    ),
    (
        Whitespace,
        43..44,
    ),
    (
        Text(
            "important",
        ),
        44..53,
    ),
    (
        Whitespace,
        53..54,
    ),
    (
        Text(
            "note",
        ),
        54..58,
    ),
    (
        Whitespace,
        58..59,
    ),
    (
        Text(
            "that",
        ),
        59..63,
    ),
    (
        Whitespace,
        63..64,
    ),
    (
        Text(
            "requires",
        ),
        64..72,
    ),
    (
        Whitespace,
        72..73,
    ),
    (
        Text(
            "a",
        ),
        73..74,
    ),
    (
        Whitespace,
        74..75,
    ),
    (
        Text(
            "detailed",
        ),
        75..83,
    ),
    (
        Whitespace,
        83..84,
    ),
    (
        Text(
            "explanation",
        ),
        84..95,
    ),
    (
        Period,
        95..96,
    ),
    (
        Newline,
        96..97,
    ),
    (
        BlankLine(
            [
                (
                    Newline,
                    97..98,
                ),
            ],
        ),
        0..0,
    ),
    (
        Text(
            "It",
        ),
        102..104,
    ),
    (
        Whitespace,
        104..105,
    ),
    (
        Text(
            "can",
        ),
        105..108,
    ),
    (
        Whitespace,
        108..109,
    ),
    (
        Text(
            "span",
        ),
        109..113,
    ),
    (
        Whitespace,
        113..114,
    ),
    (
        Text(
            "multiple",
        ),
        114..122,
    ),
    (
        Whitespace,
        122..123,
    ),
    (
        Text(
            "paragraphs",
        ),
        123..133,
    ),
    (
        Whitespace,
        133..134,
    ),
    (
        Text(
            "to",
        ),
        134..136,
    ),
    (
        Whitespace,
        136..137,
    ),
    (
        Text(
            "provide",
        ),
        137..144,
    ),
    (
        Whitespace,
        144..145,
    ),
    (
        Text(
            "comprehensive",
        ),
        145..158,
    ),
    (
        Whitespace,
        158..159,
    ),
    (
        Text(
            "information",
        ),
        159..170,
    ),
    (
        Period,
        170..171,
    ),
    (
        Newline,
        171..172,
    ),
    (
        Dedent(
            [],
        ),
        0..0,
    ),
    (
        LexMarker,
        172..174,
    ),
    (
        Newline,
        174..175,
    ),
]
