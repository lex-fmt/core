---
source: tests/tokenizer_elements.rs
expression: tokens.tokens()
---
[
    (
        LexMarker,
        0..2,
    ),
    (
        Whitespace,
        2..3,
    ),
    (
        Text(
            "warning",
        ),
        3..10,
    ),
    (
        Whitespace,
        10..11,
    ),
    (
        Text(
            "severity",
        ),
        11..19,
    ),
    (
        Equals,
        19..20,
    ),
    (
        Text(
            "high",
        ),
        20..24,
    ),
    (
        Whitespace,
        24..25,
    ),
    (
        LexMarker,
        25..27,
    ),
    (
        Whitespace,
        27..28,
    ),
    (
        Text(
            "Check",
        ),
        28..33,
    ),
    (
        Whitespace,
        33..34,
    ),
    (
        Text(
            "this",
        ),
        34..38,
    ),
    (
        Whitespace,
        38..39,
    ),
    (
        Text(
            "carefully",
        ),
        39..48,
    ),
    (
        Newline,
        48..49,
    ),
]
