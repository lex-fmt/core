---
source: tests/tokenizer_elements.rs
expression: tokens.tokens()
---
[
    (
        Text(
            "Test",
        ),
        0..4,
    ),
    (
        Colon,
        4..5,
    ),
    (
        Newline,
        5..6,
    ),
    (
        BlankLine(
            [
                (
                    Newline,
                    6..7,
                ),
            ],
        ),
        0..0,
    ),
    (
        Text(
            "I",
        ),
        7..8,
    ),
    (
        Period,
        8..9,
    ),
    (
        Whitespace,
        9..10,
    ),
    (
        Text(
            "First",
        ),
        10..15,
    ),
    (
        Whitespace,
        15..16,
    ),
    (
        Text(
            "roman",
        ),
        16..21,
    ),
    (
        Whitespace,
        21..22,
    ),
    (
        Text(
            "item",
        ),
        22..26,
    ),
    (
        Newline,
        26..27,
    ),
    (
        Text(
            "II",
        ),
        27..29,
    ),
    (
        Period,
        29..30,
    ),
    (
        Whitespace,
        30..31,
    ),
    (
        Text(
            "Second",
        ),
        31..37,
    ),
    (
        Whitespace,
        37..38,
    ),
    (
        Text(
            "roman",
        ),
        38..43,
    ),
    (
        Whitespace,
        43..44,
    ),
    (
        Text(
            "item",
        ),
        44..48,
    ),
    (
        Newline,
        48..49,
    ),
    (
        Text(
            "III",
        ),
        49..52,
    ),
    (
        Period,
        52..53,
    ),
    (
        Whitespace,
        53..54,
    ),
    (
        Text(
            "Third",
        ),
        54..59,
    ),
    (
        Whitespace,
        59..60,
    ),
    (
        Text(
            "roman",
        ),
        60..65,
    ),
    (
        Whitespace,
        65..66,
    ),
    (
        Text(
            "item",
        ),
        66..70,
    ),
    (
        Newline,
        70..71,
    ),
]
