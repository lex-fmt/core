---
source: lex-parser/tests/tokenizer_elements.rs
expression: tokens
---
[
    (
        Text(
            "This",
        ),
        0..4,
    ),
    (
        Whitespace(
            1,
        ),
        4..5,
    ),
    (
        Text(
            "paragraph",
        ),
        5..14,
    ),
    (
        Whitespace(
            1,
        ),
        14..15,
    ),
    (
        Text(
            "has",
        ),
        15..18,
    ),
    (
        Whitespace(
            1,
        ),
        18..19,
    ),
    (
        Text(
            "some",
        ),
        19..23,
    ),
    (
        Whitespace(
            1,
        ),
        23..24,
    ),
    (
        Text(
            "special",
        ),
        24..31,
    ),
    (
        Whitespace(
            1,
        ),
        31..32,
    ),
    (
        Text(
            "characters",
        ),
        32..42,
    ),
    (
        Colon,
        42..43,
    ),
    (
        Whitespace(
            1,
        ),
        43..44,
    ),
    (
        ExclamationMark,
        44..45,
    ),
    (
        Text(
            "@#$%^&*",
        ),
        45..52,
    ),
    (
        OpenParen,
        52..53,
    ),
    (
        CloseParen,
        53..54,
    ),
    (
        Text(
            "_+",
        ),
        54..56,
    ),
    (
        Dash,
        56..57,
    ),
    (
        Equals,
        57..58,
    ),
    (
        Text(
            "[]{}|",
        ),
        58..63,
    ),
    (
        Semicolon,
        63..64,
    ),
    (
        Text(
            "'",
        ),
        64..65,
    ),
    (
        Colon,
        65..66,
    ),
    (
        Quote,
        66..67,
    ),
    (
        Comma,
        67..68,
    ),
    (
        Period,
        68..69,
    ),
    (
        Text(
            "/<>",
        ),
        69..72,
    ),
    (
        QuestionMark,
        72..73,
    ),
    (
        BlankLine(
            Some(
                "\n",
            ),
        ),
        73..74,
    ),
]
